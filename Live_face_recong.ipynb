{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV25Ww2PWNjb",
        "outputId": "8426f5e3-2baa-4278-9e42-c4034589eca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement csv (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for csv\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "pip install opencv-python numpy csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-contrib-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek98Wo81WPPZ",
        "outputId": "260d3b09-fb66-4c6a-cda9-02717a19f418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-contrib-python) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmMbhhaZYTlV",
        "outputId": "f6872e3e-1cad-4b9a-8d79-29f079ce293b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.6)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import csv\n",
        "import mediapipe as mp\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from base64 import b64decode\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, Javascript\n",
        "\n",
        "# Initialize FaceMesh for Liveness Detection\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
        "\n",
        "# Webcam Photo Capture (Google Colab)\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            capture.textContent = 'Capture';\n",
        "            div.appendChild(capture);\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "            await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js(f'takePhoto({quality})')\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    return filename\n",
        "\n",
        "\n",
        "class LivenessDetector:\n",
        "    def __init__(self):\n",
        "        self.ear_history = []\n",
        "        self.nose_positions = []\n",
        "        self.blink_count = 0\n",
        "        self.movement_threshold = 10  # Adjusted for better detection\n",
        "        self.ear_threshold = 0.21\n",
        "        self.avg_movement = 0\n",
        "\n",
        "    def calculate_ear(self, eye_landmarks):\n",
        "        d1 = np.linalg.norm(eye_landmarks[1] - eye_landmarks[5])\n",
        "        d2 = np.linalg.norm(eye_landmarks[2] - eye_landmarks[4])\n",
        "        d3 = np.linalg.norm(eye_landmarks[0] - eye_landmarks[3])\n",
        "        return (d1 + d2) / (2 * d3)\n",
        "\n",
        "    def detect(self, image):\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        results = face_mesh.process(image_rgb)\n",
        "\n",
        "        if not results.multi_face_landmarks:\n",
        "            return False\n",
        "\n",
        "        landmarks = results.multi_face_landmarks[0].landmark\n",
        "        h, w, _ = image.shape\n",
        "\n",
        "        left_eye = np.array([(landmarks[i].x * w, landmarks[i].y * h)\n",
        "                           for i in [33, 160, 158, 133, 153, 144]])\n",
        "        right_eye = np.array([(landmarks[i].x * w, landmarks[i].y * h)\n",
        "                            for i in [362, 385, 387, 263, 373, 380]])\n",
        "        nose = (landmarks[4].x * w, landmarks[4].y * h)\n",
        "\n",
        "        left_ear = self.calculate_ear(left_eye)\n",
        "        right_ear = self.calculate_ear(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2\n",
        "\n",
        "        self.ear_history.append(avg_ear)\n",
        "        if len(self.ear_history) > 5:\n",
        "            self.ear_history.pop(0)\n",
        "\n",
        "        if len(self.ear_history) == 5:\n",
        "            if (self.ear_history[0] > self.ear_threshold and\n",
        "                min(self.ear_history[1:4]) < self.ear_threshold and\n",
        "                self.ear_history[4] > self.ear_threshold):\n",
        "                self.blink_count += 1\n",
        "                print(f\"Blink detected! Total blinks: {self.blink_count}\")\n",
        "\n",
        "        self.nose_positions.append(nose)\n",
        "        if len(self.nose_positions) > 10:\n",
        "            self.nose_positions.pop(0)\n",
        "\n",
        "        if len(self.nose_positions) >= 2:\n",
        "            movements = [np.linalg.norm(np.array(a)-np.array(b))\n",
        "                        for a,b in zip(self.nose_positions[1:], self.nose_positions[:-1])]\n",
        "            self.avg_movement = np.mean(movements)\n",
        "        else:\n",
        "            self.avg_movement = 0\n",
        "\n",
        "        return self.blink_count >= 2 and self.avg_movement > self.movement_threshold\n",
        "\n",
        "class FaceAttendanceSystem:\n",
        "    def __init__(self):\n",
        "        self.face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "        self.face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
        "        self.dataset_dir = \"dataset\"\n",
        "        self.registered_names = []\n",
        "        os.makedirs(self.dataset_dir, exist_ok=True)\n",
        "\n",
        "        if os.path.exists(\"registered_names.npy\"):\n",
        "            self.registered_names = np.load(\"registered_names.npy\", allow_pickle=True).tolist()\n",
        "\n",
        "    def register_face(self):\n",
        "        name = input(\"Enter your name: \").strip()\n",
        "        if name in self.registered_names:\n",
        "            print(\"User already exists!\")\n",
        "            return\n",
        "\n",
        "        person_dir = os.path.join(self.dataset_dir, name)\n",
        "        os.makedirs(person_dir, exist_ok=True)\n",
        "\n",
        "        print(\"Capturing images... Look at the camera and blink/move your head.\")\n",
        "        for i in range(10):\n",
        "            filename = os.path.join(person_dir, f\"{i}.jpg\")\n",
        "            take_photo(filename)\n",
        "            print(f\"Captured {i+1}/10\")\n",
        "\n",
        "        self.registered_names.append(name)\n",
        "        np.save(\"registered_names.npy\", self.registered_names)\n",
        "        print(\"✅ Face registered successfully!\")\n",
        "\n",
        "        print(\"🔄 Training model...\")\n",
        "        self.train_model()\n",
        "        print(\"✅ Model trained successfully!\")\n",
        "\n",
        "    def train_model(self):\n",
        "        faces, labels = [], []\n",
        "        label_map = {name: idx for idx, name in enumerate(self.registered_names)}\n",
        "\n",
        "        for name, label in label_map.items():\n",
        "            person_dir = os.path.join(self.dataset_dir, name)\n",
        "            for filename in os.listdir(person_dir):\n",
        "                img_path = os.path.join(person_dir, filename)\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                faces.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "        self.face_recognizer.train(faces, np.array(labels))\n",
        "        self.face_recognizer.save(\"trained_model.yml\")\n",
        "\n",
        "    def log_attendance(self, name, action):\n",
        "        tz = pytz.timezone('Asia/Karachi')\n",
        "        now = datetime.now(tz)\n",
        "        date_str, time_str = now.strftime(\"%Y-%m-%d\"), now.strftime(\"%H:%M:%S\")\n",
        "        csv_path = os.path.join(os.getcwd(), \"attendance.csv\")\n",
        "\n",
        "        file_exists = os.path.isfile(csv_path)\n",
        "        with open(csv_path, \"a\", newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            if not file_exists:\n",
        "                writer.writerow([\"Name\", \"Date\", \"Time\", \"Action\"])\n",
        "            writer.writerow([name, date_str, time_str, action])\n",
        "        print(f\"✅ {name} marked {action} at {date_str} {time_str}\")\n",
        "\n",
        "    def recognize_face(self, action_type):\n",
        "        if not os.path.exists(\"trained_model.yml\"):\n",
        "            print(\"❌ No trained model found! Register a user first.\")\n",
        "            return\n",
        "\n",
        "        self.face_recognizer.read(\"trained_model.yml\")\n",
        "\n",
        "        print(f\"🔍 Performing liveness check for {action_type}...\")\n",
        "        while True:\n",
        "            filename = take_photo()\n",
        "            image = cv2.imread(filename)\n",
        "            if image is None:\n",
        "                continue\n",
        "\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            faces = self.face_detector.detectMultiScale(gray, 1.1, 5)\n",
        "\n",
        "            for (x, y, w, h) in faces:\n",
        "                label, conf = self.face_recognizer.predict(gray[y:y+h, x:x+w])\n",
        "                name = self.registered_names[label] if conf < 100 else \"Unknown\"\n",
        "\n",
        "                if name != \"Unknown\":\n",
        "                    self.log_attendance(name, action_type)\n",
        "                    print(f\"✅ {name} logged {action_type} successfully!\")\n",
        "                    os.remove(filename)\n",
        "                    return\n",
        "            os.remove(filename)\n",
        "            if input(\"Press 'q' to quit: \").lower() == 'q':\n",
        "                break\n",
        "\n",
        "# Main Program\n",
        "if __name__ == \"__main__\":\n",
        "    system = FaceAttendanceSystem()\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n1. Register Face\\n2. Log In\\n3. Log Out\\n4. Exit\")\n",
        "        choice = input(\"Choose option: \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            system.register_face()\n",
        "        elif choice == '2':\n",
        "            system.recognize_face(\"in\")\n",
        "        elif choice == '3':\n",
        "            system.recognize_face(\"out\")\n",
        "        elif choice == '4':\n",
        "            break\n",
        "        else:\n",
        "            print(\"❌ Invalid choice! Please try again.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "zHNgla089QCq",
        "outputId": "7249efdd-209e-45eb-b732-b4032c171d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. Register Face\n",
            "2. Log In\n",
            "3. Log Out\n",
            "4. Exit\n",
            "Choose option: 2\n",
            "🔍 Performing liveness check for in...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const capture = document.createElement('button');\n",
              "            capture.textContent = 'Capture';\n",
              "            div.appendChild(capture);\n",
              "\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "            await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Hassan marked in at 2025-02-19 12:07:32\n",
            "✅ Hassan logged in successfully!\n",
            "\n",
            "1. Register Face\n",
            "2. Log In\n",
            "3. Log Out\n",
            "4. Exit\n",
            "Choose option: 3\n",
            "🔍 Performing liveness check for out...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const capture = document.createElement('button');\n",
              "            capture.textContent = 'Capture';\n",
              "            div.appendChild(capture);\n",
              "\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "            await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Hassan marked out at 2025-02-19 12:07:42\n",
            "✅ Hassan logged out successfully!\n",
            "\n",
            "1. Register Face\n",
            "2. Log In\n",
            "3. Log Out\n",
            "4. Exit\n",
            "Choose option: 4\n"
          ]
        }
      ]
    }
  ]
}